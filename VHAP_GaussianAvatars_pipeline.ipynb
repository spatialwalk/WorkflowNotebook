{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VHAP + GaussianAvatars 全流程自动化\n",
    "\n",
    "本 notebook 实现以下流程：  \n",
    "1. 依次运行 VHAP 的 Preprocess、Track、Export 三个阶段  \n",
    "2. 运行 GaussianAvatars 的训练脚本  \n",
    "3. 对训练好的模型进行测试（渲染），并输出测试视频  \n",
    "\n",
    "注意！：请将你的视频素材放在“/root/autodl-tmp/datasets/”位置\n",
    "\n",
    "注意！请根据实际情况修改参数设置：  \n",
    "DATA_FOLDER为你的输入视频存储路径（视频序列的父路径）；  \n",
    "SEQUENCE为视频序列名（无.mp4的后缀）；  \n",
    "DOWNSAMPLE_SCALES为视频下采样倍数（下采样后的分辨率为700左右即可，如1440分辨率的视频，取下采样倍数为2）。\n",
    "\n",
    "注意！VHAP和GaussianAvatars两个阶段用的内核不同：  \n",
    "跑VHAP阶段时需要选择VHAP内核\n",
    "跑GaussianAvatars阶段时需选择gaussian-avatars内核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "DATA_FOLDER=\"/root/autodl-tmp/datasets/ai_video\"     # 视频数据集父路径\n",
    "SEQUENCE=\"ai_wyz_croped_150_20s\"           # 视频序列名\n",
    "DOWNSAMPLE_SCALES=\"2\"                        # 画面下采样倍数\n",
    "GPU_IDS=\"0\"\n",
    "\n",
    "# 因为运行完VHAP后要切换gaussian-avatars的kernel，所以要将前面的变量保存为文件，切换kernel再读取\n",
    "import json\n",
    "variables = {\n",
    "    \"DATA_FOLDER\": DATA_FOLDER,\n",
    "    \"SEQUENCE\": SEQUENCE,\n",
    "    \"GPU_IDS\": GPU_IDS\n",
    "}\n",
    "\n",
    "# 将字典保存到 JSON 文件中\n",
    "with open('/root/autodl-tmp/variables.json', 'w') as f:\n",
    "    json.dump(variables, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. VHAP 三阶段依次运行\n",
    "\n",
    "直接运行 VHAP 的 run_monocular.sh 脚本，包含 Preprocess、Track、Export 三个阶段。\n",
    "### 1.1. Preprocess预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "os.chdir('/root/autodl-tmp/VHAP')\n",
    "DATE_TAG = datetime.now().strftime(\"%Y%m%d\")    # 获取当前日期标签\n",
    "DATA_FOLDER_NAME = os.path.basename(DATA_FOLDER.rstrip('/'))    # 获取数据集名称（父路径文件夹名）\n",
    "\n",
    "RAW_VIDEO_PATH = f\"{DATA_FOLDER}/{SEQUENCE}.mp4\"\n",
    "preprocess_command = [\n",
    "    \"python\", \"vhap/preprocess_video.py\",\n",
    "    \"--input\", RAW_VIDEO_PATH,\n",
    "    \"--downsample_scales\", DOWNSAMPLE_SCALES,\n",
    "    \"--target_fps\", \"25\",\n",
    "    \"--matting_method\", \"rembg\"\n",
    "]\n",
    "\n",
    "os.makedirs(f\"logs/{DATA_FOLDER_NAME}\", exist_ok=True)\n",
    "print(\"开始预处理阶段...\")\n",
    "with open(f\"logs/{DATA_FOLDER_NAME}/{DATE_TAG}_{SEQUENCE}_preprocess_log.txt\", \"w\") as logf:\n",
    "    subprocess.run(\n",
    "        preprocess_command,\n",
    "        env=dict(os.environ, CUDA_VISIBLE_DEVICES=GPU_IDS),\n",
    "        stdout=logf,\n",
    "        stderr=subprocess.STDOUT\n",
    "    )\n",
    "print(\"预处理阶段完成\")\n",
    "print(f\"预处理后的结果保存在{DATA_FOLDER}/{SEQUENCE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Track跟踪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"/root/autodl-tmp/VHAP_track/{DATA_FOLDER_NAME}/output\", exist_ok=True)\n",
    "TRACK_OUTPUT_FOLDER = f\"/root/autodl-tmp/VHAP_track/{DATA_FOLDER_NAME}/output/{SEQUENCE}\"\n",
    "track_command = [\n",
    "    \"python\", \"vhap/track.py\",\n",
    "    \"--data.root_folder\", DATA_FOLDER,\n",
    "    \"--exp.output_folder\", TRACK_OUTPUT_FOLDER,\n",
    "    \"--data.sequence\", SEQUENCE,\n",
    "    \"--data.n_downsample_rgb\", DOWNSAMPLE_SCALES,\n",
    "    \"--data.landmark_source\", \"dslpt\"\n",
    "]\n",
    "\n",
    "os.makedirs(f\"logs/{DATA_FOLDER_NAME}\", exist_ok=True)\n",
    "print(\"开始跟踪阶段...\")\n",
    "with open(f\"logs/{DATA_FOLDER_NAME}/{DATE_TAG}_{SEQUENCE}_track_log.txt\", \"w\") as logf:\n",
    "    subprocess.run(\n",
    "        track_command,\n",
    "        env=dict(os.environ, CUDA_VISIBLE_DEVICES=GPU_IDS),\n",
    "        stdout=logf,\n",
    "        stderr=subprocess.STDOUT\n",
    "    )\n",
    "print(\"跟踪阶段完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. 导出阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"/root/autodl-tmp/VHAP_track/{DATA_FOLDER_NAME}/export\", exist_ok=True)\n",
    "EXPORT_OUTPUT_FOLDER = f\"/root/autodl-tmp/VHAP_track/{DATA_FOLDER_NAME}/export/{SEQUENCE}\"\n",
    "export_command = [\n",
    "    \"python\", \"vhap/export_as_nerf_dataset.py\",\n",
    "    \"--src_folder\", TRACK_OUTPUT_FOLDER,\n",
    "    \"--tgt_folder\", EXPORT_OUTPUT_FOLDER,\n",
    "    \"--background-color\", \"white\",\n",
    "    \"--epoch\", \"0\"\n",
    "]\n",
    "\n",
    "print(\"开始导出阶段...\")\n",
    "with open(f\"logs/{DATA_FOLDER_NAME}/{DATE_TAG}_{SEQUENCE}_export_log.txt\", \"w\") as logf:\n",
    "    subprocess.run(\n",
    "        export_command,\n",
    "        env=dict(os.environ, CUDA_VISIBLE_DEVICES=GPU_IDS),\n",
    "        stdout=logf,\n",
    "        stderr=subprocess.STDOUT\n",
    "    )\n",
    "print(\"导出阶段完成\")\n",
    "print(f\"导出阶段完成，导出结果存储在：{EXPORT_OUTPUT_FOLDER}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GaussianAvatars 训练\n",
    "\n",
    "进行 GaussianAvatars 的训练，注意切换选择内核为gaussian-avatars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练阶段...\n",
      "训练阶段完成\n",
      "训练阶段完成，高斯模型存储在：/root/autodl-tmp/gaussian_avatars_output/ai_video/ai_wyz_croped_150_20s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "# 从 JSON 文件中加载变量\n",
    "with open('/root/autodl-tmp/variables.json', 'r') as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "# 将变量重新赋值\n",
    "DATA_FOLDER = variables[\"DATA_FOLDER\"]\n",
    "SEQUENCE = variables[\"SEQUENCE\"]\n",
    "GPU_IDS = variables[\"GPU_IDS\"]\n",
    "DATA_FOLDER_NAME = os.path.basename(DATA_FOLDER.rstrip('/'))\n",
    "DATE_TAG = datetime.now().strftime(\"%Y%m%d\")\n",
    "EXPORT_OUTPUT_FOLDER = f\"/root/autodl-tmp/VHAP_track/{DATA_FOLDER_NAME}/export/{SEQUENCE}_epoch0\"\n",
    "\n",
    "# 进入 GaussianAvatars 目录，训练GaussianAvatars\n",
    "os.chdir('/root/autodl-tmp/GaussianAvatars')\n",
    "\n",
    "# 定义变量\n",
    "os.makedirs(f\"/root/autodl-tmp/gaussian_avatars_output/{DATA_FOLDER_NAME}/{SEQUENCE}\", exist_ok=True)\n",
    "GAUSSIANAVATARS_MODEL_FOLDER = f\"/root/autodl-tmp/gaussian_avatars_output/{DATA_FOLDER_NAME}/{SEQUENCE}\"\n",
    "PORT = 60000 + random.randint(1, 100)\n",
    "\n",
    "# 定义训练命令\n",
    "train_command = [\n",
    "    \"python\", \"train.py\",\n",
    "    \"-s\", EXPORT_OUTPUT_FOLDER,\n",
    "    \"-m\", GAUSSIANAVATARS_MODEL_FOLDER,\n",
    "    \"--bind_to_mesh\",\n",
    "    \"--white_background\",\n",
    "    \"--port\", str(PORT),\n",
    "    \"--resolution\", \"1\",\n",
    "    \"--data_device\", \"cpu\",\n",
    "    \"--sh_degree\", \"0\",\n",
    "    \"--iteration\", \"60000\"\n",
    "]\n",
    "\n",
    "# 打印开始信息\n",
    "print(\"开始训练阶段...\")\n",
    "\n",
    "# 运行训练命令\n",
    "with open(f\"/root/autodl-tmp/gaussian_avatars_output/{DATA_FOLDER_NAME}/{SEQUENCE}.log\", \"w\") as logf:\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            train_command,\n",
    "            env=dict(os.environ, CUDA_VISIBLE_DEVICES=GPU_IDS),\n",
    "            stdout=logf,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            check=True\n",
    "        )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"训练阶段失败，错误信息：{e}\")\n",
    "\n",
    "# 打印完成信息\n",
    "print(\"训练阶段完成\")\n",
    "print(f\"训练阶段完成，高斯模型存储在：{GAUSSIANAVATARS_MODEL_FOLDER}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GaussianAvatars 测试（渲染）并输出视频\n",
    "\n",
    "### 3.1. 自驱动渲染"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始自驱动渲染阶段...\n",
      "自驱动渲染阶段完成\n",
      "渲染结果预览:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"/root/autodl-tmp/gaussian_avatars_output/ai_video/ai_wyz_croped_150_20s/ai_wyz_croped_150_20s_epoch0_0/ours_60000/renders_no_audio.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 定义渲染命令\n",
    "render_command = [\n",
    "    \"python\", \"render.py\",\n",
    "    \"-s\", EXPORT_OUTPUT_FOLDER,\n",
    "    \"-m\", GAUSSIANAVATARS_MODEL_FOLDER,\n",
    "    \"-t\", EXPORT_OUTPUT_FOLDER,\n",
    "    \"--select_camera_id\", \"0\",\n",
    "    \"--iteration\", \"60000\"\n",
    "]\n",
    "\n",
    "# 打印开始信息\n",
    "print(\"开始自驱动渲染阶段...\")\n",
    "\n",
    "# 运行渲染命令\n",
    "try:\n",
    "    with open(f\"/root/autodl-tmp/gaussian_avatars_output/{DATA_FOLDER_NAME}/{SEQUENCE}_self_driven_render.log\", \"w\") as logf:\n",
    "        subprocess.run(\n",
    "            render_command,\n",
    "            env=dict(os.environ, CUDA_VISIBLE_DEVICES=GPU_IDS),\n",
    "            stdout=logf,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            check=True\n",
    "    )\n",
    "except subprocess.CalledProcessError as e:\n",
    "        print(f\"渲染阶段失败，错误信息：{e}\")\n",
    "\n",
    "# 打印完成信息\n",
    "print(\"自驱动渲染阶段完成\")\n",
    "# 获取渲染结果视频路径\n",
    "render_output_video = f\"{GAUSSIANAVATARS_MODEL_FOLDER}/{SEQUENCE}_epoch0_0/ours_60000/renders_no_audio.mp4\"\n",
    "\n",
    "# 检查视频文件是否存在\n",
    "if os.path.exists(render_output_video):\n",
    "    # 显示渲染结果视频\n",
    "    from IPython.display import Video\n",
    "    print(\"渲染结果预览:\")\n",
    "    display(Video(render_output_video))\n",
    "else:\n",
    "    print(f\"未找到渲染结果视频: {render_output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. diffposetalk驱动渲染\n",
    "\n",
    "#### 先调整diffposetalk的flame和相机transforms参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理 FLAME和Transforms 转换...\n",
      "步骤1: 开始组合flame_param数据...\n",
      "no_head: False\n",
      "adjust_neck_mean: True\n",
      "计算得到的coef neck_pose均值: [[ 0.06217049 -0.00764011 -0.01637743]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 193/250 [00:00<00:00, 317.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤1完成: 已生成250帧flame_param数据到 /root/autodl-tmp/test_diffposetalk_data_for_gs_render/default-peter-TH050-small-head-movements-adjust/flame_param\n",
      "步骤2: 开始复制transforms json文件...\n",
      "已复制 /root/autodl-fs/test_diffposetalk_data_for_gs_render/transforms_train.json 到 /root/autodl-tmp/test_diffposetalk_data_for_gs_render/default-peter-TH050-small-head-movements-adjust/transforms_train.json\n",
      "已复制 /root/autodl-fs/test_diffposetalk_data_for_gs_render/transforms_test.json 到 /root/autodl-tmp/test_diffposetalk_data_for_gs_render/default-peter-TH050-small-head-movements-adjust/transforms_test.json\n",
      "已复制 /root/autodl-fs/test_diffposetalk_data_for_gs_render/transforms_val.json 到 /root/autodl-tmp/test_diffposetalk_data_for_gs_render/default-peter-TH050-small-head-movements-adjust/transforms_val.json\n",
      "步骤2完成: 已复制transforms json文件到 /root/autodl-tmp/test_diffposetalk_data_for_gs_render/default-peter-TH050-small-head-movements-adjust\n",
      "步骤3: 开始更新transforms_train.json配置...\n",
      "步骤3完成: 已更新JSON文件，共包含250帧数据\n",
      "已使用来自 /root/autodl-tmp/VHAP_track/ai_video/export/ai_wyz_croped_150_20s_epoch0/transforms_train.json 的相机参数\n",
      "所有步骤已完成!\n",
      "FLAME和Transforms 转换处理完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 318.42it/s]\n"
     ]
    }
   ],
   "source": [
    "DIFFPOSETALK_DATA = \"/root/autodl-tmp/test_diffposetalk_data_for_gs_render/default-peter-TH050-small-head-movements-adjust\"\n",
    "REFERENCE_FLAME_PATH = f\"{EXPORT_OUTPUT_FOLDER}/flame_param/00000.npz\"\n",
    "REFERENCE_JSON_PATH = f\"{EXPORT_OUTPUT_FOLDER}/transforms_train.json\"\n",
    "\n",
    "# 定义命令\n",
    "command = [\n",
    "    \"python\", \"/root/autodl-tmp/test_diffposetalk_data_for_gs_render/process_flame_transforms.py\",\n",
    "    \"--base_path\", DIFFPOSETALK_DATA,\n",
    "    \"--reference_flame_path\", REFERENCE_FLAME_PATH,\n",
    "    \"--reference_json_path\", REFERENCE_JSON_PATH,\n",
    "    \"--adjust-neck-mean\"\n",
    "]\n",
    "\n",
    "# 打印开始信息\n",
    "print(\"开始处理 FLAME和Transforms 转换...\")\n",
    "\n",
    "# 运行命令\n",
    "try:\n",
    "    subprocess.run(command, check=True)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"处理 FLAME和Transforms 转换失败，错误信息：{e}\")\n",
    "\n",
    "# 打印完成信息\n",
    "print(\"FLAME和Transforms 转换处理完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始diffposetalk-peter驱动渲染阶段...\n",
      "diffposetalk-peter驱动渲染阶段完成\n",
      "正在展示渲染视频...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"/root/autodl-tmp/gaussian_avatars_output/ai_video/ai_wyz_croped_150_20s/default-peter-TH050-small-head-movements-adjust_0/ours_60000/renders_no_audio.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 定义渲染命令\n",
    "render_command = [\n",
    "    \"python\", \"render.py\",\n",
    "    \"-s\", EXPORT_OUTPUT_FOLDER,\n",
    "    \"-m\", GAUSSIANAVATARS_MODEL_FOLDER,\n",
    "    \"-t\", DIFFPOSETALK_DATA,\n",
    "    \"--select_camera_id\", \"0\",\n",
    "    \"--iteration\", \"60000\"\n",
    "]\n",
    "\n",
    "# 打印开始信息\n",
    "print(\"开始diffposetalk-peter驱动渲染阶段...\")\n",
    "\n",
    "# 运行渲染命令\n",
    "try:\n",
    "    with open(f\"/root/autodl-tmp/gaussian_avatars_output/{DATA_FOLDER_NAME}/{SEQUENCE}_diffposetalk_driven_render.log\", \"w\") as logf:\n",
    "        subprocess.run(\n",
    "            render_command,\n",
    "            env=dict(os.environ, CUDA_VISIBLE_DEVICES=GPU_IDS),\n",
    "            stdout=logf,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            check=True\n",
    "    )\n",
    "except subprocess.CalledProcessError as e:\n",
    "        print(f\"diffposetalk-peter驱动渲染阶段失败，错误信息：{e}\")\n",
    "\n",
    "# 打印完成信息\n",
    "print(\"diffposetalk-peter驱动渲染阶段完成\")\n",
    "\n",
    "# 展示渲染得到的视频\n",
    "# 导入Video类用于显示视频\n",
    "from IPython.display import Video\n",
    "\n",
    "# 获取渲染视频路径\n",
    "render_video_path = f\"{GAUSSIANAVATARS_MODEL_FOLDER}/default-peter-TH050-small-head-movements-adjust_0/ours_60000/renders_no_audio.mp4\"\n",
    "\n",
    "# 检查视频文件是否存在\n",
    "if os.path.exists(render_video_path):\n",
    "    print(\"正在展示渲染视频...\")\n",
    "    display(Video(render_video_path))\n",
    "else:\n",
    "    print(f\"未找到渲染视频文件: {render_video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型导出\n",
    "\n",
    "导出各个文件并打包\n",
    "\n",
    "注意:\n",
    "你需要选取你希望的呼吸态的开始和结束时间\n",
    "你需要选取一段你希望的独白的开始和结束时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDLE_START_TIME = \"0\"\n",
    "IDLE_END_TIME = \"3\"\n",
    "\n",
    "MONOLOGUE_START_TIME = \"0\"\n",
    "MONOLOGUE_END_TIME = \"20\"\n",
    "\n",
    "os.makedirs(\"/root/autodl-tmp/export_ios_client/{DATA_FOLDER_NAME}/{SEQUENCE}\", exist_ok=True)\n",
    "os.makedirs(\"/root/autodl-tmp/export_ios_client/{DATA_FOLDER_NAME}/{SEQUENCE}/idle_flame\", exist_ok=True)\n",
    "GSMODEL_EXPORT_FOLDER = \"/root/autodl-tmp/export_ios_client/{DATA_FOLDER_NAME}/{SEQUENCE}\"\n",
    "\n",
    "# 导出3dgs点云\n",
    "!cp -r {GAUSSIANAVATARS_MODEL_FOLDER}/point_cloud/iteration_600000/point_cloud.ply {GSMODEL_EXPORT_FOLDER}\n",
    "\n",
    "# 导出训练时的训练时候的首帧flame\n",
    "!cp -r {EXPORT_OUTPUT_FOLDER}/flame_param/00000.npz {GSMODEL_EXPORT_FOLDER}\n",
    "\n",
    "# 提取呼吸态flame（正序+倒序）\n",
    "!python root/autodl-tmp/scripts/extract_flames_split.py \\\n",
    "    --src_dir /path/to/source \\\n",
    "    --dst_dir /path/to/destination/idle \\\n",
    "    --start_time IDLE_START_TIME \\\n",
    "    --end_time IDLE_END_TIME \\\n",
    "    --fps 25 \\\n",
    "    --mode idle\n",
    "\n",
    "# 提取独白flame（仅正序）\n",
    "!python root/autodl-tmp/scripts/extract_flames_split.py \\\n",
    "    --src_dir /path/to/source \\\n",
    "    --dst_dir /path/to/destination/monologue \\\n",
    "    --start_time MONOLOGUE_START_TIME \\\n",
    "    --end_time MONOLOGUE_END_TIME \\\n",
    "    --fps 25 \\\n",
    "    --mode monologue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VHAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
